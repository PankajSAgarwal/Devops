1. Docker Engine

- is simply referred to a host with Docker installed on it.

2. When you install a docker on a linux host you are actually installing 3 different components.

Docker Engine
  • Docker CLI
  • REST API
  • Docker Daemon

3. Docker Daemon 
- is a background process that manages docker objects such as images , containers, volumes and networks.

4. Docker Rest API server 

- is the API interface that programs can use to talk to the daemon and provide instructions.You could create your own tools using the REST API

5. Docker CLI

- is the command line interface that we have been using until now to perform actions such as running a container , stopping a containers , destroying images etc.

It uses the rest api to interact with the docker daemon .

6. Docker CLI does not need to be necessarily be on the same host.
Docker CLI can be on a seperate system like laptop an still work with a remote docker engine.

Simply use the -H option on the docker command and specify the remote docker engine address and the port

e.g to run a container based on nginx on a remote docker host, run the command

docker -H=10.123.2.1:2375 run nginx

7. Docker uses namespace to isolate workspace, process ids, network, inter process communication, mounts and unix time sharing systems are created in their own namespace thereby providing isolation between containers.

8. Lets take a look at one of the namespace isolation technique Process ID namespace.

- Whenever a linux system boots up it starts with just one process with a process-id of just 1 . This is the root process and kicks off all the other processes in the system.
- By the time system boots up completely, we have a handful of processes running . This can be seen by running the ps command to list all the running processes.The process id are unique and two processes cannot have the same process id

- Now if we were to create a container which is basically a child system with in the current system, the child system needs to think that it is an independent system on its own and it has its own set of processes originating from a root process with a process id of 1.

But we know there is no hard isolation between the containers and the underlying host system.So the process running inside the container are in fact processes running on the underlying host.And so two processes cannot have the same process id of 1 .This is where namespaces come into play.

With processes id namespaces, each process can have multiple process ids associated with it. For e,g when the processes start in the container its actually just another set of processes on the base linux system and it gets the next available process id.However they also get another process id starting with PID 1 in the container namespace which is only visible inside the container. So the container thinks that it has its own root process tree and so it is an independent system.

9. How does the concepts in point 8 relate to actual system. How do u see this on a host . 

- Let say i have to run a nginx server as a container. We know that an nginx container runs an nginx service. 

- if we were to list all the services inside the docker container , we see that nginx service running with a process id of 1 . This is the process id of the service inside of the container namespace.

- if we list the services on a docker host we will see the same service but with a different process id . That indicates infact all services are running on the same host but seperated into their own containers using the namespace.

10 .So we learnt that underlying docker host as well as the containers share the same system resources such as CPU or memory. 

11. How much of the resources is dedicated to the host and the containers and how does docker manage and share the resources between the containers ?

- By default there is no restriction as to how much of a resource a container can use and hence a container may end up utilizing all of the resources on the underlying host.

But there is a way to restrict the amount of CPU or memory a container can use. 
Docker uses 3 groups or control groups to restrict the amount of hardware resources allocated to each container.

e.g docker run --cpus=.5 ubuntu

a value of .5 in above command ensures that the container does not take up more than 50% of the host CPU at any given time.

e.g docker run --memory=100m ubuntu

setting a value of 100 --memory option limits the the amount of memory the container can use to 100 mb

