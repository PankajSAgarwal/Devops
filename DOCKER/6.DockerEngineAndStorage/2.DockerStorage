1. How docker stores data on local filesystem.

- When you install docker on a system it creates the folder structure at 
/var/lib/docker .
- You have multiple folders under it called aufs , containers, image, volumes etc. 

This is where docker stores all its data by default.

e.g all files related to containers are stored in /var/lib/docker/containers
and all file related to images are stored in /var/lib/docker/image

Any volume created by the docker container created under the
 /var/lib/docker/volumes folder.

2. Docker Layered Architecture

- When docker build images it builds it in layered architecture.
- Each line of instruction in the docker file creates a new layer in the docker image with just the changes from the previous layer

Dockerfile
FROM Ubuntu
RUN apt-get update && apt-get -y install python
RUN pip install flask flask-mysql
COPY . /opt/source-code
ENTRYPOINT FLASK_APP=/opt/source-code/app.py flask

Layer1 : Base Ubuntu layer
Layer2 : Changes in apt packages
Layer3 : Changes in pip packages
Layer4 : Source code
Layer5 : Update Entrypoint

3. To understand the advantages of layered architecture, consider 2 similar docker files as shown below

// Docker file 1

Dockerfile                                                              
FROM Ubuntu
RUN apt-get update && apt-get -y install python
RUN pip install flask flask-mysql
COPY . /opt/source-code
ENTRYPOINT FLASK_APP=/opt/source-code/app.py flask

docker build Dockerfile -t pankaj/my-custom-app

// Docker file2

Dockerfile2                                                              
FROM Ubuntu
RUN apt-get update && apt-get -y install python
RUN pip install flask flask-mysql
COPY app2.py /opt/source-code
ENTRYPOINT FLASK_APP=/opt/source-code/app2.py flask run

docker build Dockerfile2 -t pankaj/my-custom-app-2

• When i run the docker build command to build a new image for the second application, since the first 3 layers of both the applications are same , Docker is not going to build the first 3 layers.Instead it reuses the same 3 layers from the cache and only creates the last two layers with the new sources and the new entry point . This way docker build images faster and efficiently saves disk space.

• This is also applicable whenever you update your application code.
Whenever you update your application code such as the app.ui , in this case Docker re-uses all the previous layers from cache and quickly rebuilds the application image by updating the latest source code thus saving us a lot of time during rebuilds and updates.

4. Lets rearrange the layer in bottom up order


Layer5 : Update Entrypoint
Layer4 : Source code
Layer3 : Changes in pip packages
Layer2 : Changes in apt packages
Layer1 : Base Ubuntu layer

All of these layers are created when u run the docker build command to form the final docker image.

Once the build is complete you cannot modify the contents of this layer and they are read only and you can only modify them by initiating a new build.

When u run a container based off this image using the docker run command, docker creates a container based off these layers and creates a new writeable layer on top of the image layer.

The writeable layer is used to store data created by the container by the container such as log files by the application, any temporary files generated by the container or any file modified by the user on that container.

The life of this layer is though only as long as the container is alive.

When the container is destroyed, this layer and all of the changes stored in it are also destroyed.

Remember that the same image layer is shared by all containers created using this image .

If i were to log into the newly created container and create a new file called temp.txt , it would create that file in the container layer which is read and write.



docker run pankaj/my-custom-app

          Layer 6: Read and Write Container Layer 
   -----------------------------------------------------------------------
  |      Image layer- Read-only                                           |
  |                                                                       |
  |      Layer5 : Update Entrypoint                                       |     
  |      Layer4 : Source code                                             | 
  |      Layer3 : Changes in pip packages                                 | 
  |      Layer2 : Changes in apt packages                                 |
  |      Layer1 : Base Ubuntu layer                                       | 
   ----------------------------------------------------------------------

5. Since the application code is baked into the image , the code is part of the image layer and as such is read only.After running the container, what if i want to modify the source code to test a change.

Remember same image layer may be shared between multiple containers created from this image. So does it mean i cannot modify this file inside the container. No , i can still modify this file but before i save the modified file, Docker automatically creates a copy of the file in read write layer and i will then be modifying a different version of the file in the read write layer.

All future modifications will be done on this copy of the file in the read write layer.This is called copy on write mechanism.

The image layer being read only just means the files in these layers will not be modified in the iage itself, so the image will remain the same all the time until you rebuild the image using docker build command.

6. What happens when we get rid of the container?

All of the data thatw as stored in the container layer also gets deleted.
The change that we did to the source code will also be deleted when container is deleted.

7. Volumes

• What if we wish to persist this data

- For example,if we were working with a database and we would like to preserve the data created by the container we could add a persistent volume to the container. To do this first create a volume using the docker volume create command

• docker volume create data_volume

-> It creates a data_volume folder under /var/lib/docker/volumes directory.

-> Then when i run the docker container using the docker run command i could mount this volume inside the docker containers read write layer using the -v option.

• docker run -v data_volume:/var/lib/mysql mysql

The above command will create a new container and mount the data volume we created into /var/lib/mysql folder inside the container. So all data written by the database is in fact stored on the volume created on the docker host.

Even if the container is destroyed, data is still active.

Now what if you didnt run the docker volume create command to create the volume before  the docker run command.

e.g if i run the command directly

• docker run -v data_volume2:/var/lib/mysql mysql

docker will automatically create a volume named data_volume2 and mount it on the container.

You should be able to see all these volumes if you list the contents of the /var/lib/docker/volumes folder 

This is called volume mounting as we are mounting the volume created by docker under the /var/lib/docker/volumes folder.

8. What if we had our data already at another location for example, lets say we have some external storage on the docker host at /data and we would like to store database data on that volume and not in the default /var/lib/docker/volumes folder

In that case we would run a container using the command 

• docker run -v /data/mysql:/var/lib/mysql mysql

So it will create a container and mount the folder to the container.

This called bind mounting.

9. So there are two types of mounting , a volume mounting and a bind mount.

Volume mount mounts a volume from the volume directory and bind mount mounts a directory from any location on the docker host.

10.-v is an old style , using -mount is the new way

--mount is prefered way

docker run --mount type=bind,source=/data/mysql, target=/var/lib/mysql mysql

source - location at the docker host
target - location at the container

11. Who is responsible for doing all these tasks 
  - maintaining layered architecture
  - creating a writeable layer 
  - moving files across layers to enable copy and write etc

Ans : Its the storage drivers . Docker uses storage drivers to enable layered architecture

Some of the common storage drivers are

• AUFS
• ZFS
• BTRFS
• Device Mapper
• Overlay
• Overlay 2

Selection of storage driver depends on the underlying OS being used . For example with Ubuntu, the default storage is AUFS whereas this storage driver is not available on other OS like fedora or centos.
In that case Device Mapper might be a better option.

Docker will automatically choose the best Storage driver based on the OS




